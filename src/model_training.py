# src/model_training.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, confusion_matrix, 
                           classification_report, roc_curve)
import joblib
import warnings
warnings.filterwarnings('ignore')

class ModelTrainer:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.models = {}
        self.results = {}
        self.best_model = None
        self.best_score = 0
        
    def prepare_data(self, df, target_col='target', test_size=0.2):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        print("ğŸ“Š ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨...")
        
        X = df.drop(columns=[target_col])
        y = df[target_col]
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state, stratify=y
        )
        
        print(f"ğŸ“ˆ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {X_train.shape}")
        print(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {X_test.shape}")
        print(f"ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {pd.Series(y_train).value_counts().to_dict()}")
        print(f"ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {pd.Series(y_test).value_counts().to_dict()}")
        
        return X_train, X_test, y_train, y_test
    
    def initialize_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
        
        models = {
            'Logistic Regression': LogisticRegression(
                random_state=self.random_state, max_iter=1000
            ),
            'Decision Tree': DecisionTreeClassifier(
                random_state=self.random_state
            ),
            'Random Forest': RandomForestClassifier(
                n_estimators=100, random_state=self.random_state
            ),
            'SVM': SVC(
                probability=True, random_state=self.random_state
            ),
            'K-Nearest Neighbors': KNeighborsClassifier(),
            'Gradient Boosting': GradientBoostingClassifier(
                random_state=self.random_state
            )
        }
        
        return models
    
    def train_models(self, X_train, X_test, y_train, y_test):
        """ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
        
        models = self.initialize_models()
        results = []
        
        for name, model in models.items():
            print(f"\nğŸ“š ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬: {name}")
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.fit(X_train, y_train)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0
            
            # Ø§Ù„ØªÙ‚Ø§Ø·Ø¹ Ø¹Ø¨Ø± k-fold
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            cv_mean = cv_scores.mean()
            cv_std = cv_scores.std()
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            model_results = {
                'Model': name,
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall,
                'F1-Score': f1,
                'AUC-ROC': auc,
                'CV Mean': cv_mean,
                'CV Std': cv_std,
                'Model Object': model
            }
            
            results.append(model_results)
            
            print(f"   âœ… Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.4f}")
            print(f"   âœ… F1-Score: {f1:.4f}")
            print(f"   âœ… AUC-ROC: {auc:.4f}")
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø£ÙØ¶Ù„
            if accuracy > self.best_score:
                self.best_score = accuracy
                self.best_model = model
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame
        results_df = pd.DataFrame(results)
        self.results = results_df
        self.models = {row['Model']: row['Model Object'] for _, row in results_df.iterrows()}
        
        return results_df
    
    def plot_model_comparison(self):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        if self.results.empty:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
            return
        
        print("\nğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        results_sorted = self.results.sort_values('Accuracy', ascending=False)
        
        # Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
        fig, axes = plt.subplots(2, 2, figsize=(18, 12))
        
        # Ø§Ù„Ø¯Ù‚Ø©
        axes[0,0].barh(results_sorted['Model'], results_sorted['Accuracy'], color='skyblue')
        axes[0,0].set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬')
        axes[0,0].set_xlabel('Ø§Ù„Ø¯Ù‚Ø©')
        
        # F1-Score
        axes[0,1].barh(results_sorted['Model'], results_sorted['F1-Score'], color='lightcoral')
        axes[0,1].set_title('Ù…Ù‚Ø§Ø±Ù†Ø© F1-Score Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬')
        axes[0,1].set_xlabel('F1-Score')
        
        # AUC-ROC
        axes[1,0].barh(results_sorted['Model'], results_sorted['AUC-ROC'], color='lightgreen')
        axes[1,0].set_title('Ù…Ù‚Ø§Ø±Ù†Ø© AUC-ROC Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬')
        axes[1,0].set_xlabel('AUC-ROC')
        
        # Ø§Ù„ØªÙ‚Ø§Ø·Ø¹
        axes[1,1].barh(results_sorted['Model'], results_sorted['CV Mean'], 
                      xerr=results_sorted['CV Std'], color='gold')
        axes[1,1].set_title('Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙ‚Ø§Ø·Ø¹ (5-fold)')
        axes[1,1].set_xlabel('Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©')
        
        plt.tight_layout()
        plt.show()
        
        # Ø¹Ø±Ø¶ Ø£ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        print("\nğŸ¯ Ø£ÙØ¶Ù„ 3 Ù†Ù…Ø§Ø°Ø¬:")
        top_3 = results_sorted.head(3)
        for _, model in top_3.iterrows():
            print(f"   {model['Model']}:")
            print(f"      ğŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {model['Accuracy']:.4f}")
            print(f"      ğŸ¯ F1-Score: {model['F1-Score']:.4f}")
            print(f"      ğŸ“ˆ AUC-ROC: {model['AUC-ROC']:.4f}")
    
    def plot_confusion_matrices(self, X_test, y_test):
        """Ø±Ø³Ù… Ù…ØµÙÙˆÙØ§Øª Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬"""
        print("\nğŸ“‹ Ø±Ø³Ù… Ù…ØµÙÙˆÙØ§Øª Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ...")
        
        n_models = len(self.models)
        n_cols = 3
        n_rows = (n_models + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 5))
        axes = axes.flatten()
        
        for i, (name, model) in enumerate(self.models.items()):
            if i < len(axes):
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                y_pred = model.predict(X_test)
                
                # Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ
                cm = confusion_matrix(y_test, y_pred)
                
                # Ø§Ù„Ø±Ø³Ù…
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                           xticklabels=['Ø³Ù„ÙŠÙ…', 'Ù…Ø±ÙŠØ¶'], 
                           yticklabels=['Ø³Ù„ÙŠÙ…', 'Ù…Ø±ÙŠØ¶'])
                axes[i].set_title(f'Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ - {name}')
                axes[i].set_xlabel('Ø§Ù„ØªÙ†Ø¨Ø¤')
                axes[i].set_ylabel('Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©')
        
        # Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ©
        for i in range(len(self.models), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.show()
    
    def plot_roc_curves(self, X_test, y_test):
        """Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª ROC Ù„Ù„Ù†Ù…Ø§Ø°Ø¬"""
        print("\nğŸ“ˆ Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª ROC...")
        
        plt.figure(figsize=(12, 8))
        
        for name, model in self.models.items():
            if hasattr(model, "predict_proba"):
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                auc_score = roc_auc_score(y_test, y_pred_proba)
                
                plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})', linewidth=2)
        
        # Ø®Ø· Ø§Ù„Ù…Ø±Ø¬Ø¹
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø´ÙˆØ§Ø¦ÙŠ')
        
        plt.xlabel('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„ÙƒØ§Ø°Ø¨Ø©')
        plt.ylabel('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©')
        plt.title('Ù…Ù†Ø­Ù†ÙŠØ§Øª ROC Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
    
    def save_models(self, models_path='models/'):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""
        import os
        os.makedirs(models_path, exist_ok=True)
        
        print(f"ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙÙŠ {models_path}...")
        
        for name, model in self.models.items():
            # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ù„Ù
            filename = name.lower().replace(' ', '_') + '.pkl'
            filepath = os.path.join(models_path, filename)
            
            joblib.dump(model, filepath)
            print(f"   âœ… ØªÙ… Ø­ÙØ¸ {name} ÙÙŠ {filename}")
        
        # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
        if self.best_model is not None:
            best_model_path = os.path.join(models_path, 'best_model.pkl')
            joblib.dump(self.best_model, best_model_path)
            print(f"   ğŸ† ØªÙ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ best_model.pkl")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results_path = os.path.join(models_path, 'training_results.csv')
        self.results.to_csv(results_path, index=False)
        print(f"   ğŸ“Š ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ training_results.csv")
    
    def train_complete_pipeline(self, df, target_col='target'):
        """Ø®Ø·Ø© ØªØ¯Ø±ÙŠØ¨ ÙƒØ§Ù…Ù„Ø©"""
        print("ğŸ¯ Ø¨Ø¯Ø¡ Ø®Ø·Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„Ø©...")
        
        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_test, y_train, y_test = self.prepare_data(df, target_col)
        
        # 2. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        results_df = self.train_models(X_train, X_test, y_train, y_test)
        
        # 3. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.plot_model_comparison()
        
        # 4. Ù…ØµÙÙˆÙØ§Øª Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ
        self.plot_confusion_matrices(X_test, y_test)
        
        # 5. Ù…Ù†Ø­Ù†ÙŠØ§Øª ROC
        self.plot_roc_curves(X_test, y_test)
        
        # 6. Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.save_models()
        
        print("\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        return results_df

# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©
def train_all_models(df, target_col='target'):
    trainer = ModelTrainer()
    results = trainer.train_complete_pipeline(df, target_col)
    return results, trainer