# src/feature_selection.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE, SelectKBest, chi2, f_classif
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

class FeatureSelector:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.selected_features = None
        self.feature_importance_df = None
        
    def random_forest_importance(self, X, y, n_features=10):
        """Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest"""
        print("ðŸŒ² Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest...")
        
        rf = RandomForestClassifier(n_estimators=100, random_state=self.random_state)
        rf.fit(X, y)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        importance_scores = rf.feature_importances_
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': importance_scores
        }).sort_values('importance', ascending=False)
        
        # Ø±Ø³Ù… Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        plt.figure(figsize=(12, 8))
        sns.barplot(data=feature_importance.head(n_features), 
                   x='importance', y='feature', palette='viridis')
        plt.title(f'Ø£Ù‡Ù… {n_features} Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest')
        plt.xlabel('Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©')
        plt.tight_layout()
        plt.show()
        
        return feature_importance, rf
    
    def recursive_feature_elimination(self, X, y, n_features=8):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ© RFE"""
        print("ðŸ”„ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ© (RFE)...")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ Ù…Ø¹ RFE
        estimator = LogisticRegression(random_state=self.random_state, max_iter=1000)
        rfe = RFE(estimator=estimator, n_features_to_select=n_features)
        rfe.fit(X, y)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        rfe_results = pd.DataFrame({
            'feature': X.columns,
            'rfe_ranking': rfe.ranking_,
            'rfe_selected': rfe.support_
        }).sort_values('rfe_ranking')
        
        print(f"Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø¨ÙˆØ§Ø³Ø·Ø© RFE:")
        selected_features = rfe_results[rfe_results['rfe_selected']]['feature'].tolist()
        for feature in selected_features:
            print(f"  âœ… {feature}")
        
        return rfe_results, rfe
    
    def statistical_feature_selection(self, X, y, k=8):
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©"""
        print("ðŸ“Š Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©...")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… ANOVA F-test
        selector = SelectKBest(score_func=f_classif, k='all')
        selector.fit(X, y)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        statistical_scores = pd.DataFrame({
            'feature': X.columns,
            'f_score': selector.scores_,
            'p_value': selector.pvalues_
        }).sort_values('f_score', ascending=False)
        
        # Ø±Ø³Ù… Ù†ØªØ§Ø¦Ø¬ F-test
        plt.figure(figsize=(12, 8))
        significant_features = statistical_scores[statistical_scores['p_value'] < 0.05]
        
        if len(significant_features) > 0:
            sns.barplot(data=significant_features.head(k), 
                       x='f_score', y='feature', palette='plasma')
            plt.title('Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ANOVA F-test (p-value < 0.05)')
            plt.xlabel('F-score')
            plt.tight_layout()
            plt.show()
        else:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙŠØ²Ø§Øª Ø°Ø§Øª Ø¯Ù„Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© (p-value < 0.05)")
        
        return statistical_scores, selector
    
    def compare_feature_sets(self, X, y, methods_results):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØªØ§Ø¦Ø¬ Ø·Ø±Ù‚ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        print("\nðŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØªØ§Ø¦Ø¬ Ø·Ø±Ù‚ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª...")
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚
        all_selected_features = set()
        feature_scores = {}
        
        for method_name, (results, _) in methods_results.items():
            if method_name == 'random_forest':
                top_features = results.head(10)['feature'].tolist()
            elif method_name == 'rfe':
                top_features = results[results['rfe_selected']]['feature'].tolist()
            elif method_name == 'statistical':
                top_features = results.head(10)['feature'].tolist()
            
            all_selected_features.update(top_features)
            
            # ØªØ¹ÙŠÙŠÙ† Ø¯Ø±Ø¬Ø§Øª Ù„Ù„Ù…ÙŠØ²Ø§Øª
            for i, feature in enumerate(top_features):
                if feature not in feature_scores:
                    feature_scores[feature] = 0
                feature_scores[feature] += (len(top_features) - i)
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø­Ø³Ø¨ Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
        final_ranking = pd.DataFrame({
            'feature': list(all_selected_features),
            'composite_score': [feature_scores[feature] for feature in all_selected_features]
        }).sort_values('composite_score', ascending=False)
        
        # Ø±Ø³Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        plt.figure(figsize=(12, 8))
        sns.barplot(data=final_ranking.head(12), x='composite_score', y='feature', palette='coolwarm')
        plt.title('Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©')
        plt.xlabel('Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©')
        plt.tight_layout()
        plt.show()
        
        return final_ranking
    
    def select_final_features(self, X, y, top_k=8):
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©"""
        print("ðŸŽ¯ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚
        rf_importance, rf_model = self.random_forest_importance(X, y)
        rfe_results, rfe_selector = self.recursive_feature_elimination(X, y)
        statistical_results, stats_selector = self.statistical_feature_selection(X, y)
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        methods_results = {
            'random_forest': (rf_importance, rf_model),
            'rfe': (rfe_results, rfe_selector),
            'statistical': (statistical_results, stats_selector)
        }
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_ranking = self.compare_feature_sets(X, y, methods_results)
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        self.selected_features = final_ranking.head(top_k)['feature'].tolist()
        self.feature_importance_df = final_ranking
        
        print(f"\nðŸŽ‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© ({top_k} Ù…ÙŠØ²Ø§Øª):")
        for i, feature in enumerate(self.selected_features, 1):
            print(f"  {i}. {feature}")
        
        return self.selected_features, methods_results
    
    def get_reduced_dataset(self, df, target_col='target'):
        """Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© ÙÙ‚Ø·"""
        if self.selected_features is None:
            raise ValueError("ÙŠØ¬Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ select_final_features Ø£ÙˆÙ„Ø§Ù‹")
        
        features_to_keep = self.selected_features + [target_col]
        reduced_df = df[features_to_keep]
        
        print(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(self.selected_features)} Ù…ÙŠØ²Ø© Ù…Ù† Ø£ØµÙ„ {len(df.columns)-1}")
        print(f"ðŸ“Š Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª: {reduced_df.shape}")
        
        return reduced_df

# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©
def perform_feature_selection(df, target_col='target', top_k=8):
    selector = FeatureSelector()
    selected_features, methods_results = selector.select_final_features(
        df.drop(columns=[target_col]), 
        df[target_col], 
        top_k
    )
    reduced_df = selector.get_reduced_dataset(df, target_col)
    
    return reduced_df, selected_features, methods_results, selector