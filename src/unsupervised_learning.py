# src/unsupervised_learning.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score, adjusted_rand_score, confusion_matrix
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
import warnings
warnings.filterwarnings('ignore')

class UnsupervisedLearning:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.cluster_models = {}
        self.clustering_results = {}
        
    def prepare_data_for_clustering(self, df, target_col='target'):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¬Ù…ÙŠØ¹"""
        print("ğŸ“Š ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¬Ù…ÙŠØ¹...")
        
        # ÙØµÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
        X = df.drop(columns=[target_col])
        y = df[target_col]
        
        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        return X_scaled, y, scaler
    
    def find_optimal_clusters_kmeans(self, X, max_k=15):
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù„ØªØ¬Ù…Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… K-Means"""
        print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù„ØªØ¬Ù…Ø¹Ø§Øª (K-Means)...")
        
        wcss = []  # Within-Cluster Sum of Squares
        silhouette_scores = []
        
        k_range = range(2, max_k + 1)
        
        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init=10)
            kmeans.fit(X)
            
            wcss.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(X, kmeans.labels_))
        
        # Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Elbow
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # Ù…Ù†Ø­Ù†Ù‰ Elbow
        axes[0].plot(k_range, wcss, marker='o', color='#FF6B6B', linewidth=2)
        axes[0].set_xlabel('Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª (K)')
        axes[0].set_ylabel('WCSS')
        axes[0].set_title('Ù…Ù†Ø­Ù†Ù‰ Elbow Ù„Ù€ K-Means')
        axes[0].grid(True, alpha=0.3)
        
        # Ù…Ù†Ø­Ù†Ù‰ Silhouette
        axes[1].plot(k_range, silhouette_scores, marker='o', color='#4ECDC4', linewidth=2)
        axes[1].set_xlabel('Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª (K)')
        axes[1].set_ylabel('Ù…ØªÙˆØ³Ø· Silhouette Score')
        axes[1].set_title('Ù…Ù†Ø­Ù†Ù‰ Silhouette Ù„Ù€ K-Means')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ K
        optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]
        print(f"ğŸ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù„ØªØ¬Ù…Ø¹Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Silhouette Score: {optimal_k_silhouette}")
        
        return optimal_k_silhouette, wcss, silhouette_scores
    
    def apply_kmeans_clustering(self, X, n_clusters=2):
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ¬Ù…ÙŠØ¹ K-Means"""
        print(f"ğŸ”„ ØªØ·Ø¨ÙŠÙ‚ K-Means Ù…Ø¹ {n_clusters} ØªØ¬Ù…Ø¹Ø§Øª...")
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=self.random_state, n_init=10)
        kmeans_labels = kmeans.fit_predict(X)
        
        # Ø­Ø³Ø§Ø¨ Silhouette Score
        silhouette_avg = silhouette_score(X, kmeans_labels)
        print(f"   âœ… Silhouette Score: {silhouette_avg:.4f}")
        
        self.cluster_models['kmeans'] = kmeans
        self.clustering_results['kmeans'] = {
            'model': kmeans,
            'labels': kmeans_labels,
            'silhouette_score': silhouette_avg
        }
        
        return kmeans, kmeans_labels
    
    def plot_dendrogram(self, X, method='ward'):
        """Ø±Ø³Ù… Dendrogram Ù„Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ"""
        print("ğŸŒ³ Ø±Ø³Ù… Dendrogram Ù„Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ...")
        
        plt.figure(figsize=(12, 8))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
        linked = linkage(X, method=method)
        
        # Ø±Ø³Ù… Dendrogram
        dendrogram(linked, orientation='top', 
                  distance_sort='descending', 
                  show_leaf_counts=True)
        
        plt.title('Dendrogram Ù„Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ')
        plt.xlabel('Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
        plt.ylabel('Ø§Ù„Ù…Ø³Ø§ÙØ©')
        plt.grid(True, alpha=0.3)
        plt.show()
        
        return linked
    
    def apply_hierarchical_clustering(self, X, n_clusters=2, method='ward'):
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ"""
        print(f"ğŸŒ³ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ Ù…Ø¹ {n_clusters} ØªØ¬Ù…Ø¹Ø§Øª...")
        
        hierarchical = AgglomerativeClustering(
            n_clusters=n_clusters, 
            metric='euclidean', 
            linkage=method
        )
        hierarchical_labels = hierarchical.fit_predict(X)
        
        # Ø­Ø³Ø§Ø¨ Silhouette Score
        silhouette_avg = silhouette_score(X, hierarchical_labels)
        print(f"   âœ… Silhouette Score: {silhouette_avg:.4f}")
        
        self.cluster_models['hierarchical'] = hierarchical
        self.clustering_results['hierarchical'] = {
            'model': hierarchical,
            'labels': hierarchical_labels,
            'silhouette_score': silhouette_avg
        }
        
        return hierarchical, hierarchical_labels
    
    def visualize_clusters(self, X, cluster_labels, y_true, algorithm_name):
        """ØªØµÙˆØ± Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PCA"""
        print(f"ğŸ¨ ØªØµÙˆØ± ØªØ¬Ù…Ø¹Ø§Øª {algorithm_name}...")
        
        # ØªØ·Ø¨ÙŠÙ‚ PCA Ù„Ù„ØªØµÙˆØ±
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X)
        
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        # Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, 
                                 cmap='viridis', alpha=0.7, s=50)
        axes[0].set_title(f'Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ - Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨')
        axes[0].set_xlabel('Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ 1')
        axes[0].set_ylabel('Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ 2')
        plt.colorbar(scatter1, ax=axes[0], label='Ù…Ø±Ø¶ Ø§Ù„Ù‚Ù„Ø¨')
        
        # Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, 
                                 cmap='plasma', alpha=0.7, s=50)
        axes[1].set_title(f'ØªØ¬Ù…Ø¹Ø§Øª {algorithm_name}')
        axes[1].set_xlabel('Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ 1')
        axes[1].set_ylabel('Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ 2')
        plt.colorbar(scatter2, ax=axes[1], label='Ø§Ù„ØªØ¬Ù…Ø¹')
        
        plt.tight_layout()
        plt.show()
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        unique_clusters = np.unique(cluster_labels)
        print(f"\nğŸ“Š ØªØ­Ù„ÙŠÙ„ ØªØ¬Ù…Ø¹Ø§Øª {algorithm_name}:")
        for cluster in unique_clusters:
            cluster_indices = np.where(cluster_labels == cluster)[0]
            true_labels_in_cluster = y_true.iloc[cluster_indices] if hasattr(y_true, 'iloc') else y_true[cluster_indices]
            
            disease_ratio = np.mean(true_labels_in_cluster)
            print(f"   Ø§Ù„ØªØ¬Ù…Ø¹ {cluster}: {len(cluster_indices)} Ø¹ÙŠÙ†Ø©ØŒ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø±Ø¶: {disease_ratio:.2%}")
    
    def compare_clustering_algorithms(self, X, y):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        print("ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹...")
        
        comparison_results = []
        
        for algo_name, results in self.clustering_results.items():
            labels = results['labels']
            silhouette = results['silhouette_score']
            
            # Adjusted Rand Score Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
            ari = adjusted_rand_score(y, labels)
            
            comparison_results.append({
                'Algorithm': algo_name,
                'Silhouette Score': silhouette,
                'Adjusted Rand Index': ari,
                'Number of Clusters': len(np.unique(labels))
            })
            
            print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ {algo_name}:")
            print(f"   Silhouette Score: {silhouette:.4f}")
            print(f"   Adjusted Rand Index: {ari:.4f}")
        
        # Ø±Ø³Ù… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        comparison_df = pd.DataFrame(comparison_results)
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # Silhouette Score
        axes[0].bar(comparison_df['Algorithm'], comparison_df['Silhouette Score'], 
                   color=['#FF6B6B', '#4ECDC4'])
        axes[0].set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Silhouette Score')
        axes[0].set_ylabel('Silhouette Score')
        axes[0].tick_params(axis='x', rotation=45)
        
        # Adjusted Rand Index
        axes[1].bar(comparison_df['Algorithm'], comparison_df['Adjusted Rand Index'],
                   color=['#45B7D1', '#96CEB4'])
        axes[1].set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Adjusted Rand Index')
        axes[1].set_ylabel('Adjusted Rand Index')
        axes[1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()
        
        return comparison_df
    
    def analyze_cluster_characteristics(self, df, cluster_labels, target_col='target'):
        """ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ ÙƒÙ„ ØªØ¬Ù…Ø¹"""
        print("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª...")
        
        df_analysis = df.copy()
        df_analysis['Cluster'] = cluster_labels
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ ØªØ¬Ù…Ø¹
        cluster_stats = df_analysis.groupby('Cluster').agg({
            'age': ['mean', 'std'],
            'chol': ['mean', 'std'],
            'trestbps': ['mean', 'std'],
            'thalach': ['mean', 'std'],
            target_col: ['mean', 'count']
        }).round(2)
        
        print("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„ØªØ¬Ù…Ø¹Ø§Øª:")
        print(cluster_stats)
        
        # Ø±Ø³Ù… Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª
        numeric_features = df.select_dtypes(include=[np.number]).columns
        numeric_features = numeric_features.drop(target_col, errors='ignore')
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£Ù‡Ù… 4 Ù…ÙŠØ²Ø§Øª Ù„Ù„Ø¹Ø±Ø¶
        important_features = numeric_features[:4]
        
        n_features = len(important_features)
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, feature in enumerate(important_features):
            if i < len(axes):
                # Ù…Ø®Ø·Ø· Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ù„ÙƒÙ„ ØªØ¬Ù…Ø¹
                data_to_plot = [df_analysis[df_analysis['Cluster'] == cluster][feature] 
                              for cluster in np.unique(cluster_labels)]
                
                axes[i].boxplot(data_to_plot, labels=[f'ØªØ¬Ù…Ø¹ {c}' for c in np.unique(cluster_labels)])
                axes[i].set_title(f'ØªÙˆØ²ÙŠØ¹ {feature} Ø¹Ø¨Ø± Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª')
                axes[i].set_ylabel(feature)
                axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return df_analysis, cluster_stats
    
    def complete_unsupervised_pipeline(self, df, target_col='target'):
        """Ø®Ø·Ø© Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ù…Ø´Ø±Ù Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        print("ğŸ¯ Ø¨Ø¯Ø¡ Ø®Ø·Ø© Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ù…Ø´Ø±Ù...")
        
        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_scaled, y, scaler = self.prepare_data_for_clustering(df, target_col)
        
        # 2. Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù„ØªØ¬Ù…Ø¹Ø§Øª
        optimal_k, wcss, silhouette_scores = self.find_optimal_clusters_kmeans(X_scaled)
        
        # 3. ØªØ·Ø¨ÙŠÙ‚ K-Means
        print(f"\nğŸ”„ ØªØ·Ø¨ÙŠÙ‚ K-Means Ù…Ø¹ {optimal_k} ØªØ¬Ù…Ø¹Ø§Øª...")
        kmeans_model, kmeans_labels = self.apply_kmeans_clustering(X_scaled, optimal_k)
        self.visualize_clusters(X_scaled, kmeans_labels, y, 'K-Means')
        
        # 4. Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ
        print(f"\nğŸŒ³ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ...")
        self.plot_dendrogram(X_scaled)
        hierarchical_model, hierarchical_labels = self.apply_hierarchical_clustering(X_scaled, optimal_k)
        self.visualize_clusters(X_scaled, hierarchical_labels, y, 'Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ')
        
        # 5. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª
        comparison_df = self.compare_clustering_algorithms(X_scaled, y)
        
        # 6. ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª
        df_kmeans_analysis, kmeans_stats = self.analyze_cluster_characteristics(df, kmeans_labels, target_col)
        
        print("\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ø§Ù„Ù…Ø´Ø±Ù Ø¨Ù†Ø¬Ø§Ø­!")
        
        return {
            'kmeans_model': kmeans_model,
            'hierarchical_model': hierarchical_model,
            'comparison_results': comparison_df,
            'cluster_analysis': df_kmeans_analysis,
            'optimal_k': optimal_k
        }

# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©
def perform_unsupervised_learning(df, target_col='target'):
    unsupervised = UnsupervisedLearning()
    results = unsupervised.complete_unsupervised_pipeline(df, target_col)
    return results, unsupervised